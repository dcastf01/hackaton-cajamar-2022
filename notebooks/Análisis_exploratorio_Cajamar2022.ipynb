{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmMVaxH_GPp3"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHCpDwBKRrcZ"
      },
      "outputs": [],
      "source": [
        "!pip install seaborn\n",
        "!pip install pycaret[full]\n",
        "!pip  matplotlib==3.1.3\n",
        "!pip install pycaret-ts-alpha\n",
        "!pip install scipy>=1.5\n",
        "!pip install pystan==2.19.1.1\n",
        "!pip install Cython\n",
        "!pip install prophet\n",
        "!pip install -U kaleido\n",
        "!pip install numpy --upgrade\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/Hackaton cajamar 2022/Cajamar_Water_Footprint.zip\" \"/content/data.zip\" #in my case I use drive to upload the file\n",
        "!unzip -P  UH2022@CwF data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title subir el archivo y descomprimir\n",
        "do_upload_the_file = False #@param {type:\"boolean\"}\n",
        "if do_upload_the_file:\n",
        "    from google.colab import files\n",
        "\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "        name=fn, length=len(uploaded[fn])))\n",
        "    !unzip -P  UH2022@CwF data"
      ],
      "metadata": {
        "id": "aT1P6uUBNlTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soUcrUgdGBLg"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjSaR_21Rz_G"
      },
      "outputs": [],
      "source": [
        "#@title imports\n",
        "import pycaret\n",
        "import pandas as pd\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from prophet import Prophet\n",
        "\n",
        "%matplotlib notebook\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfisF7GxyvGD"
      },
      "outputs": [],
      "source": [
        "target='total'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_range_to_predic(start='2020-01-31',last_date='2020-01-31',periods=1,):\n",
        "       \n",
        "        freq='D'\n",
        "        dates = pd.date_range(\n",
        "            start=start,\n",
        "            periods=periods,  # An extra in case we include start\n",
        "            freq=freq)\n",
        "    \n",
        "        return dates\n",
        "def add_new_date_per_id(df_per_id_but_without_column_id,date,id_unique):\n",
        "    df_to_add_new_date=pd.DataFrame()\n",
        "   \n",
        "    df_to_add_new_date.index=get_range_to_predic(start=date,last_date=date)\n",
        "    df_to_add_new_date.index = df_to_add_new_date.index.set_names(['date'])\n",
        "    df_to_add_new_date.reset_index(inplace=True)\n",
        "    \n",
        "    df_to_add_new_date=df_to_add_new_date[df_to_add_new_date['date']==date]\n",
        "      \n",
        "    return df_to_add_new_date\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    list_of_id_with_tiny_data=[2521, 2724, 2725, 2727, 2728, 2729, 2730, 2731, 2732, 2733, 2734, 2735, 2736, 2739, 2743, 2744, 2746, 2747, 2749, 2756]\n",
        "    data_path='/content/Modelar_UH2022.txt'\n",
        "    df=pd.read_csv( data_path,sep=\"|\")\n",
        "    df=df[df['ID']<=25]\n",
        "    # df=df[df['ID'].isin(list_of_id_with_tiny_data)]\n",
        "    logging.info(df.shape)\n",
        "    df.drop(columns=['READINGINTEGER','READINGTHOUSANDTH'],inplace=True)\n",
        "    df.fillna(0,inplace=True) #check in future\n",
        "    logging.info(df.shape)\n",
        "    df.loc[:,'SAMPLETIME']=pd.to_datetime(df['SAMPLETIME'],errors='raise',format='%Y-%m-%d')\n",
        "    # df['target']\n",
        "    print(df.columns)\n",
        "    df.rename(columns={'SAMPLETIME':'date'},inplace=True)\n",
        "    df['total']=df['DELTAINTEGER']+df['DELTATHOUSANDTH']\n",
        "    df.drop(['DELTAINTEGER','DELTATHOUSANDTH'],axis=1,inplace=True)\n",
        "    print(df.columns)\n",
        "    # df=df.groupby(['ID','year','month','day'])\n",
        "    # df=df[target].sum()\n",
        "    # df=df.reset_index()\n",
        "    # df['date']=pd.to_datetime(df[['year', 'month', 'day']])\n",
        "\n",
        "    df_total=pd.DataFrame()\n",
        "    for id_unique in tqdm(df.ID.unique(),desc='creating all the dates per ID',mininterval=50):\n",
        "        df_per_id=df[df['ID']==id_unique]\n",
        "        df_per_id_but_without_column_id=df_per_id.drop('ID',axis=1)\n",
        "        list_of_df_with_new_dates=[]\n",
        "        date='2020-01-31'\n",
        "        if not df_per_id.date.isin([date]).any():\n",
        "            # print('adding',date)\n",
        "            df_with_last_date=add_new_date_per_id(df_per_id_but_without_column_id,date,id_unique)\n",
        "            list_of_df_with_new_dates.append(df_with_last_date)\n",
        "        else:print(id_unique,'ya tiene la fecha',date)\n",
        "        date='2019-02-01'\n",
        "        if not df_per_id.date.isin([date]).any():\n",
        "            # print('adding',date)\n",
        "            df_with_start_date=add_new_date_per_id(df_per_id_but_without_column_id,date,id_unique)\n",
        "            list_of_df_with_new_dates.append(df_with_start_date)\n",
        "        else:print(id_unique,'ya tiene la fecha',date)\n",
        "        if list_of_df_with_new_dates:\n",
        "            # print('list_of_df_with_new_dates')\n",
        "            df_aux=pd.concat([df_per_id_but_without_column_id,*list_of_df_with_new_dates])\n",
        "        else:    \n",
        "            df_aux=df_per_id_but_without_column_id\n",
        "            print('no_new_date')\n",
        "        # df_total.drop('ID',inplace=True,axis=1)\n",
        "        df_aux=df_aux.resample('D',on='date').sum()\n",
        "        df_aux['ID']=id_unique\n",
        "        df_total=pd.concat([df_total,df_aux])\n",
        "    return df_total.reset_index()\n",
        "\n",
        "def plot_series(time, series,i, format=\"-\", start=0, end=None):\n",
        "\n",
        "    \n",
        "    \n",
        "    plt.plot(time[start:end], series[start:end], format,label=i)\n",
        "    plt.xlabel(\"Date\")\n",
        "    plt.ylabel(\"Sales (Water)\")\n",
        "    plt.legend()"
      ],
      "metadata": {
        "id": "ALXMaNw75luV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EDA"
      ],
      "metadata": {
        "id": "t0UtTAKM34g9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##descarga de datos"
      ],
      "metadata": {
        "id": "7b0j2UZGAfco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_path='/content/Modelar_UH2022.txt'\n",
        "df_raw=pd.read_csv( data_path,sep=\"|\")\n",
        "print(df_raw.shape)\n",
        "df_raw.dtypes\n"
      ],
      "metadata": {
        "id": "DTWT5PIQOsQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.loc[:,'SAMPLETIME']=pd.to_datetime(df_raw['SAMPLETIME'],errors='raise',format='%Y-%m-%d %H:%M:%S')"
      ],
      "metadata": {
        "id": "LqZ7f7WWLHSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.info()"
      ],
      "metadata": {
        "id": "jAZW1fAFDx8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.head()"
      ],
      "metadata": {
        "id": "FIsAw-H24PzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.describe()"
      ],
      "metadata": {
        "id": "cMOLMQKiJsmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check duplicated"
      ],
      "metadata": {
        "id": "_SWXmIJGHgHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.duplicated(['ID','SAMPLETIME']).sum()\n"
      ],
      "metadata": {
        "id": "ihHf4ERHHlCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "No existen duplicados"
      ],
      "metadata": {
        "id": "MULA8F5NHx7i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto se ha descubierto que tenemos números negativos, los cuales no son posibles si es unontador de agua, por lo que analizaremos cuantos y el motivo para remediarlo"
      ],
      "metadata": {
        "id": "5XT49Ye9KMP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##casos negativos"
      ],
      "metadata": {
        "id": "Bt3DI3PEPLZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "negative_cases=df_raw[df_raw['DELTAINTEGER']<0].sort_values(['ID','SAMPLETIME'])"
      ],
      "metadata": {
        "id": "id_ftUTkJyiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_negative_id=negative_cases.ID.unique()\n",
        "len(unique_negative_id)"
      ],
      "metadata": {
        "id": "j4Ffd3eqYUVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto se observa que tenemos poco más de 8500 registros negativos comprendidos en unos casi 500 ID diferentes, vamos a analizar que ocurre para solventarlo"
      ],
      "metadata": {
        "id": "17Wlq5onKgz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw[(df_raw['ID']==3)&(df_raw['SAMPLETIME'].dt.month==5)&(df_raw['SAMPLETIME'].dt.day.isin([11,10]))].sort_values(['ID','SAMPLETIME'])"
      ],
      "metadata": {
        "id": "BJWawB1cKBhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se observa en este caso aunque exista el -1 (probablemente por alguna regulación del contador) no afecta, vamos a analizar casos más extremos"
      ],
      "metadata": {
        "id": "CA_RvfSKPDMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_raw[(df_raw['ID']==2711)].sort_values(['ID','SAMPLETIME']).tail())"
      ],
      "metadata": {
        "id": "prChuXSYPeYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw[(df_raw['ID']==2711)&(df_raw['SAMPLETIME'].dt.month==12)&(df_raw['SAMPLETIME'].dt.day.isin([15,16]))].sort_values(['ID','SAMPLETIME'])"
      ],
      "metadata": {
        "id": "6WlUCtuUPNgD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw[(df_raw['ID']==57)&(df_raw['SAMPLETIME'].dt.month==5)&(df_raw['SAMPLETIME'].dt.day.isin([18,17]))].sort_values(['ID','SAMPLETIME'])"
      ],
      "metadata": {
        "id": "a4It8jtNQ2aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suponemos que son regularizaciones aplicadas en el contador, igualmente se les ha mandado una pregunta al equipo"
      ],
      "metadata": {
        "id": "XBRbY5heRZ_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pero antes de eso vamos a ver cuales son lo smayores valores negativos"
      ],
      "metadata": {
        "id": "D_ZwU1uNr8Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw[df_raw['DELTAINTEGER']<0].sort_values(['ID','SAMPLETIME']).groupby('ID')['DELTAINTEGER'].sum().sort_values(ascending=True).head(15)"
      ],
      "metadata": {
        "id": "oOjal-e_r7-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw[df_raw['DELTAINTEGER']<0].sort_values(['ID','SAMPLETIME']).groupby('ID')['DELTAINTEGER'].count().sort_values(ascending=False).head(15)"
      ],
      "metadata": {
        "id": "_7xiTOUGsbHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw[(df_raw['ID']==2063)]['DELTAINTEGER'].plot()"
      ],
      "metadata": {
        "id": "x0hhmszur42I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw[(df_raw['ID']==2063)&(df_raw['DELTAINTEGER']<0)].sort_values(['ID','SAMPLETIME'])"
      ],
      "metadata": {
        "id": "FBpRCRDTsEx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw[(df_raw['ID']==2063)&(df_raw['SAMPLETIME'].dt.month==9)&(df_raw['SAMPLETIME'].dt.day.isin([14,15]))].sort_values(['ID','SAMPLETIME'])"
      ],
      "metadata": {
        "id": "smoHaoOYsHfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "al agruparlo por día desaparecera el valor erroneo aunque puede que no en todos los casos\n",
        "Igualmente vamos a gráficarlos y analizarlo más en detale\n"
      ],
      "metadata": {
        "id": "Ar1RoAKCsVX5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot negative id per year\n",
        "id_per_plot = 1 #@param {type:\"number\"}\n",
        "plt.figure(figsize=(20,5))\n",
        "for i, id_unique in tqdm(enumerate(unique_negative_id),desc=\"creating plots\"):\n",
        "    \n",
        "    df_aux=df_raw[df_raw['ID'] == id_unique].sort_values(['ID','SAMPLETIME'])\n",
        "    # bin=df_aux['group_by_mean_in_total'].unique()[0]\n",
        "    plot_series(df_aux['SAMPLETIME'],df_aux['DELTAINTEGER'],id_unique)\n",
        "    min=df_aux['DELTAINTEGER'].min()\n",
        "    if i %id_per_plot==0:\n",
        "        plt.ylim(min-5,abs(min)+5)\n",
        "        plt.title(f'This id is {str(id_unique)}')\n",
        "        plt.axhline(y = 0, color = 'k', linestyle = '-')\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(20,5))\n",
        "\n",
        "# 57, 301,374,379,493,635,\n",
        "#845 (un pico negativo que puede ocupar todo el vació que ha dejado por algún fallo de algo)\n",
        "#873, 907,1218,1280,1468,1487,1506,1739,1873,1884, 2063,2121\n",
        "#2711"
      ],
      "metadata": {
        "id": "2vfEVbJYaWeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dentro de los casi 500 id con valores negativos hay que darles especial atención a los siguientes 57, 301,374,379,493,635,845 873, 907,1218,1280,1468,1487,1506,1739,1873,1884, 2063,2121, 2711\n",
        "Vamos a analizarlos en profundidad y ver que tipo de problemas podemos encontrarnos\n"
      ],
      "metadata": {
        "id": "KHVjGoJCjSrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot special negative id per year\n",
        "id_per_plot = 1 #@param {type:\"number\"}\n",
        "plt.figure(figsize=(20,5))\n",
        "special_unique_negative_id=[57, 301,374,379,493,635,845,\n",
        "                            873, 907,1218,1280,1468,1487,\n",
        "                            1506,1739,1873,1884, 2063,2121,\n",
        "                            2711\n",
        "                            ]\n",
        "for i, id_unique in tqdm(enumerate(special_unique_negative_id),desc=\"creating plots\"):\n",
        "    \n",
        "    df_aux=df_raw[df_raw['ID'] == id_unique].sort_values(['ID','SAMPLETIME'])\n",
        "    # bin=df_aux['group_by_mean_in_total'].unique()[0]\n",
        "    plot_series(df_aux['SAMPLETIME'],df_aux['DELTAINTEGER'],id_unique)\n",
        "    min=df_aux['DELTAINTEGER'].min()\n",
        "    if i %id_per_plot==0:\n",
        "        plt.ylim(min-5,abs(min)+5)\n",
        "        plt.title(f'This id is {str(id_unique)}')\n",
        "        plt.axhline(y = 0, color = 'k', linestyle = '-')\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(20,5))"
      ],
      "metadata": {
        "id": "2QzgIGRqj0w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Algunos d esos problemas son: \n",
        "* El 2711 está a la inversa por lo que hay que poner todo en valor absoluto, ayudanod de esta forma a la estacionalidad.\n",
        "* Picos con valores muy altos/bajos que se compensan entre ellos como si fuera un error de lectura y luego vuelve al valor correspondiente 57,635,873,907,1218,1280,2063 estos pondremos los picos directamente a 0, ya que además casi todos los puntos son 0\n",
        "* El contador ha dejado de grabar durante un periodo de tiempo y aparece como negativo el primer valor, pero probablemente es el conjunto de valores anteriores, es el caso del 845 en este caso en concreto, después de ver la gráfica le daremos el valor de la media a los registros de valor 0\n",
        "\n",
        "* Y por último algún que otro posible pico negativo aleatorio, sin encontrar explicación ninguna, estos otros le daremos el valor de la media"
      ],
      "metadata": {
        "id": "s2_fOqVKjumy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "##Exceso de datos\n",
        "Exceso de datos, por lo que eliminamos las columnasreading y solo usamos las delta, además transformamos ambas columnas delta a una sola, donde basicamente se añaden los decimales. \n"
      ],
      "metadata": {
        "id": "-46eRoSC4VDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.drop(columns=['READINGINTEGER','READINGTHOUSANDTH'],inplace=True)\n",
        "df_raw.fillna(0,inplace=True) #check in future\n",
        "logging.info(df_raw.shape)\n",
        "df_raw.loc[:,'SAMPLETIME']=pd.to_datetime(df_raw['SAMPLETIME'],errors='raise',format='%Y-%m-%d')\n",
        "# df['target']\n",
        "print(df_raw.columns)\n",
        "df_raw.rename(columns={'SAMPLETIME':'date'},inplace=True)\n",
        "df_raw['total']=df_raw['DELTAINTEGER']+df_raw['DELTATHOUSANDTH']\n",
        "df_raw.drop(['DELTAINTEGER','DELTATHOUSANDTH'],axis=1,inplace=True)\n",
        "df_raw.head()"
      ],
      "metadata": {
        "id": "cEoVygVL4qR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_raw.describe()"
      ],
      "metadata": {
        "id": "CZ9Ty0edJXOY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Destacar que se siguen obteniendo valores negativos,"
      ],
      "metadata": {
        "id": "-Gx3LsGPJav0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No corre en colab"
      ],
      "metadata": {
        "id": "RAeauMuLAQln"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pivot table\n",
        "is_colab = True #@param {type:\"boolean\"}\n",
        "if not is_colab:\n",
        "    pivot_by_dates=df_raw.pivot(\n",
        "        index='date',\n",
        "        columns='ID',\n",
        "        values='total'\n",
        "    )\n",
        "    pivot_by_ID=df_raw.pivot(\n",
        "        index='ID',\n",
        "        columns='date',\n",
        "        values='total'\n",
        "    )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "IzMAIh4q_S8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Todos tienen las mismas fechas, existen dias que no nos dan datos?"
      ],
      "metadata": {
        "id": "pYjwsU4x8up-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo ideal es agrupar por dias o por semanas ya que es el objetivo de la competición siendo la fecha inicial el 1 de febrero de 2019 y la fecha final el 31 de enero de 2020. Para ello añadimos la primera y la última fecha a cada uno de los ID para luego realizar un resample por cada día"
      ],
      "metadata": {
        "id": "sx7P0qUs80fD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_total=pd.DataFrame()\n",
        "for id_unique in tqdm(df_raw.ID.unique(),desc='creating all the dates per ID',mininterval=50):\n",
        "    df_per_id=df_raw[df_raw['ID']==id_unique]\n",
        "    df_per_id_but_without_column_id=df_per_id.drop('ID',axis=1)\n",
        "    list_of_df_with_new_dates=[]\n",
        "    date='2020-01-31'\n",
        "    if not df_per_id.date.isin([date]).any():\n",
        "        # print('adding',date)\n",
        "        df_with_last_date=add_new_date_per_id(df_per_id_but_without_column_id,date,id_unique)\n",
        "        list_of_df_with_new_dates.append(df_with_last_date)\n",
        "    # else:print(id_unique,'ya tiene la fecha',date)\n",
        "    date='2019-02-01'\n",
        "    if not df_per_id.date.isin([date]).any():\n",
        "        # print('adding',date)\n",
        "        df_with_start_date=add_new_date_per_id(df_per_id_but_without_column_id,date,id_unique)\n",
        "        list_of_df_with_new_dates.append(df_with_start_date)\n",
        "    # else:print(id_unique,'ya tiene la fecha',date)\n",
        "    if list_of_df_with_new_dates:\n",
        "        # print('list_of_df_with_new_dates')\n",
        "        df_aux=pd.concat([df_per_id_but_without_column_id,*list_of_df_with_new_dates])\n",
        "    else:    \n",
        "        df_aux=df_per_id_but_without_column_id\n",
        "        # print('no_new_date')\n",
        "    # df_total.drop('ID',inplace=True,axis=1)\n",
        "    df_aux=df_aux.resample('D',on='date').sum()\n",
        "    df_aux['ID']=id_unique\n",
        "    df_total=pd.concat([df_total,df_aux])"
      ],
      "metadata": {
        "id": "rgEXFkZz85_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_total.head())\n",
        "df_total.shape"
      ],
      "metadata": {
        "id": "E_UZ8xmBBleS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_total.describe()"
      ],
      "metadata": {
        "id": "zdrHD1eKJTjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###exceso de negativos, casos especiales\n",
        "\n",
        "Analizamos como se portan los casos negativos especiales"
      ],
      "metadata": {
        "id": "MBsf815ql9Yt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title plot special negative id per year\n",
        "id_per_plot = 1 #@param {type:\"number\"}\n",
        "plt.figure(figsize=(20,5))\n",
        "special_unique_negative_id=[57, 301,374,379,493,635,845,\n",
        "                            873, 907,1218,1280,1468,1487,\n",
        "                            1506,1739,1873,1884, 2063,2121,\n",
        "                            2711\n",
        "                            ]\n",
        "for i, id_unique in tqdm(enumerate(special_unique_negative_id),desc=\"creating plots\"):\n",
        "    \n",
        "    df_aux=df_total[df_total['ID'] == id_unique].sort_values(['ID','date'])\n",
        "    # bin=df_aux['group_by_mean_in_total'].unique()[0]\n",
        "    plot_series(df_aux.index,df_aux['total'],id_unique)\n",
        "    min=df_aux['total'].min()\n",
        "    if i %id_per_plot==0:\n",
        "        plt.ylim(min-5,abs(min)+5)\n",
        "        plt.title(f'This id is {str(id_unique)}')\n",
        "        plt.axhline(y = 0, color = 'k', linestyle = '-')\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(20,5))"
      ],
      "metadata": {
        "id": "2XeAKCwGmAwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#existe outliers positivos??\n",
        "Se utilizo un insolation forest para tratar esto"
      ],
      "metadata": {
        "id": "8armC24U6lhH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_researching=range(0,20)\n",
        "from sklearn.ensemble import IsolationForest\n",
        "#no modificar los días después del 22 de enero\n",
        "\n",
        "\n",
        "outliers_fraction=0.01\n",
        "method_forest=IsolationForest(contamination=outliers_fraction)\n",
        "df_after_outliers=pd.DataFrame()\n",
        "plt.figure(figsize=(20,5))\n",
        "for i,id_unique in enumerate(id_researching):\n",
        "    df_per_id=df_total[df_total['ID']==id_unique].copy()\n",
        "    \n",
        "    df_per_id.head(20)\n",
        "    yhat = method_forest.fit_predict(df_per_id['total'].to_numpy().reshape(-1,1))\n",
        "    mask = yhat != -1\n",
        "    plot_series(df_per_id.index,df_per_id['total'],f'todo {id_unique}')\n",
        "    plot_series(df_per_id[mask].index,df_per_id[mask]['total'],f'true {id_unique}')\n",
        "    plot_series(df_per_id[~mask].index,df_per_id[~mask]['total'],f'mask {id_unique}')\n",
        "    plt.title('original')\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(20,5))\n",
        "    print('\\n')\n",
        "    df_per_id['total']=np.where((mask) | (df_per_id.index> '2020-01-22'),df_per_id['total'],\n",
        "            df_per_id['total'].shift(periods=7).fillna(method='bfill')\n",
        "                    \n",
        "                    )\n",
        "    plot_series(df_per_id.index,df_per_id['total'],f'todo {id_unique}')\n",
        "    plot_series(df_per_id[mask].index,df_per_id[mask]['total'],f'true {id_unique}')\n",
        "    plot_series(df_per_id[~mask].index,df_per_id[~mask]['total'],f'mask {id_unique}')\n",
        "    plt.title('modified')\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(20,5))\n",
        "    df_after_outliers=pd.concat([df_after_outliers,df_per_id])\n",
        "    print('\\n'*3)\n",
        "    if i>20:\n",
        "        break"
      ],
      "metadata": {
        "id": "1lX3Ae8V6pCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Working with pivots table"
      ],
      "metadata": {
        "id": "gTR9h3MkmofD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_total_to_pivot=df_total.reset_index()\n",
        "df_total_to_pivot"
      ],
      "metadata": {
        "id": "Sqpkva-uCJ9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_by_dates=df_total_to_pivot.pivot(\n",
        "    index='date',\n",
        "    columns='ID',\n",
        "    values='total'\n",
        ")\n",
        "pivot_by_dates"
      ],
      "metadata": {
        "id": "clldOcod_NTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#drawing one figure with title and 3 axes below each other. Size and resolution are specified\n",
        "f, axes = plt.subplots(4,1,figsize=(18,12),dpi=600,sharex=True)\n",
        "plt.suptitle('Comparison of unscaled features at different scales',fontsize=22);\n",
        "\n",
        "#drawing boxplots of three different scales, each to separate axis\n",
        "max_id=100\n",
        "sns.boxplot(data=pivot_by_dates.iloc[:,1:max_id], ax=axes[0])\n",
        "sns.boxplot(data=pivot_by_dates.iloc[:,1:max_id], ax=axes[1]).set(ylim=(0,5000))\n",
        "sns.boxplot(data=pivot_by_dates.iloc[:,1:max_id], ax=axes[2]).set(ylim=(0,2500))\n",
        "sns.boxplot(data=pivot_by_dates.iloc[:,1:max_id], ax=axes[3]).set(ylim=(0,1000))\n",
        "\n",
        "#rotating ticks of the shared x axis by 90 degrees. The shared x axis is located on axes[2]\n",
        "for tick in axes[3].get_xticklabels():\n",
        "        tick.set_rotation(90);\n",
        "\n",
        "#setting y axis labels for each axis\n",
        "for a in axes:\n",
        "    a.set_ylabel('Unscaled values');"
      ],
      "metadata": {
        "id": "0km39dPFD5Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con estos primeros 100 ID se puede observar que el rango de cada ID es muy variado, , desde 10000 de media algunos hasta muchos entre valores comprendidos menores a 1000. Se recomienda analizar el resto de ID de una forma más descriptiva, sin gráfica ya que esto solo representa el 5% aproximadamente de los datos"
      ],
      "metadata": {
        "id": "lYP4LptQGhKF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "describe_by_dates=pivot_by_dates.describe()\n",
        "describe_by_dates"
      ],
      "metadata": {
        "id": "bAgxCxhUHWqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "describe_by_dates.T"
      ],
      "metadata": {
        "id": "Mie9-5Y9awJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#drawing one figure with title and 3 axes below each other. Size and resolution are specified\n",
        "f, axes = plt.subplots(4,1,figsize=(18,12),dpi=600,sharex=True)\n",
        "plt.suptitle('Comparison of unscaled features at different scales',fontsize=22);\n",
        "\n",
        "#drawing boxplots of three different scales, each to separate axis\n",
        "max_id=100\n",
        "sns.boxplot(data=describe_by_dates.T, ax=axes[0]).set(ylim=(-5000,20000))\n",
        "sns.boxplot(data=describe_by_dates.T, ax=axes[1]).set(ylim=(0,5000))\n",
        "sns.boxplot(data=describe_by_dates.T, ax=axes[2]).set(ylim=(0,2500))\n",
        "sns.boxplot(data=describe_by_dates.T, ax=axes[3]).set(ylim=(0,1000))\n",
        "\n",
        "#rotating ticks of the shared x axis by 90 degrees. The shared x axis is located on axes[2]\n",
        "for tick in axes[3].get_xticklabels():\n",
        "        tick.set_rotation(90);\n",
        "\n",
        "#setting y axis labels for each axis\n",
        "for a in axes:\n",
        "    a.set_ylabel('Unscaled values');"
      ],
      "metadata": {
        "id": "e-n8yD0fVITX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "De esta forma se observa que la mayoría de los id tienen valores similares, con un rango intercuartilico de una amplitud de 500 en la media y desviación típica. Igual que el valor máximo tiene una gran amplitud de valores posibles y que el mínimo de normal es 0"
      ],
      "metadata": {
        "id": "MMOvgU5ibsqH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_by_id=df_total_to_pivot.pivot(\n",
        "    index='ID',\n",
        "    columns='date',\n",
        "    values='total'\n",
        ")\n",
        "pivot_by_id"
      ],
      "metadata": {
        "id": "D_3jRdKtBztI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#drawing one figure with title and 3 axes below each other. Size and resolution are specified\n",
        "f, axes = plt.subplots(4,1,figsize=(18,12),dpi=600,sharex=True)\n",
        "plt.suptitle('Comparison of unscaled features at different scales',fontsize=22);\n",
        "\n",
        "#drawing boxplots of three different scales, each to separate axis\n",
        "max_id=90 #3 meses\n",
        "sns.boxplot(data=pivot_by_id.iloc[:,1:max_id], ax=axes[0])\n",
        "sns.boxplot(data=pivot_by_id.iloc[:,1:max_id], ax=axes[1]).set(ylim=(0,5000))\n",
        "sns.boxplot(data=pivot_by_id.iloc[:,1:max_id], ax=axes[2]).set(ylim=(0,2500))\n",
        "sns.boxplot(data=pivot_by_id.iloc[:,1:max_id], ax=axes[3]).set(ylim=(0,1000))\n",
        "\n",
        "#rotating ticks of the shared x axis by 90 degrees. The shared x axis is located on axes[2]\n",
        "for tick in axes[3].get_xticklabels():\n",
        "        tick.set_rotation(90);\n",
        "\n",
        "#setting y axis labels for each axis\n",
        "for a in axes:\n",
        "    a.set_ylabel('Unscaled values');"
      ],
      "metadata": {
        "id": "it0XhIbOG29L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esta gáfica observamos que son los ID son principalmente quienes nos dan información, aunque también se puede sacar dos principales conclusiones. \n",
        "\n",
        "\n",
        "*   La primera de ellas es que la mayoría de ID tienen valores comprendidos entre 0 y 400\n",
        "*   La segunda es el efecto estacional, por ejemplo el 6 ed marzo se observa un incremento del consumo,que más o menos coincide con el inicio de las fallas de ese año. como en nuestro estudio coincide con el covid y que es para febrero eso no lo tendremos en cuenta.\n",
        "\n",
        "En relación a la estacionalidad la analizaremos más adelante\n",
        "\n"
      ],
      "metadata": {
        "id": "xYFnpDeJHa9c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "describe_by_id=pivot_by_id.describe()\n",
        "describe_by_id"
      ],
      "metadata": {
        "id": "D7jF6DUMChRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "#drawing one figure with title and 3 axes below each other. Size and resolution are specified\n",
        "f, axes = plt.subplots(4,1,figsize=(18,12),dpi=600,sharex=True)\n",
        "plt.suptitle('Comparison of unscaled features at different scales',fontsize=22);\n",
        "\n",
        "#drawing boxplots of three different scales, each to separate axis\n",
        "max_id=100\n",
        "sns.boxplot(data=describe_by_id.T, ax=axes[0]).set(ylim=(-5000,20000))\n",
        "sns.boxplot(data=describe_by_id.T, ax=axes[1]).set(ylim=(-500,5000))\n",
        "sns.boxplot(data=describe_by_id.T, ax=axes[2]).set(ylim=(-250,2500))\n",
        "sns.boxplot(data=describe_by_id.T, ax=axes[3]).set(ylim=(-100,1000))\n",
        "\n",
        "#rotating ticks of the shared x axis by 90 degrees. The shared x axis is located on axes[2]\n",
        "for tick in axes[3].get_xticklabels():\n",
        "        tick.set_rotation(90);\n",
        "\n",
        "#setting y axis labels for each axis\n",
        "for a in axes:\n",
        "    a.set_ylabel('Unscaled values');"
      ],
      "metadata": {
        "id": "xQgOluWCccWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esta gráfica podemos observar la diferencia entre los valores de las distintas fechas,variando entre 400 y 800 y donde tenemos algunos valores atípicos en la media (observable en la siguiente gráfica), probablemente por algún ID que tendrá algún valor anómalo. Además destacar la gran diferencia entre algunos ID provoca que la desviación stándar sea enorme"
      ],
      "metadata": {
        "id": "1kg_1JUbcoth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_series(describe_by_id.T.index,describe_by_id.T['mean'],'mean')"
      ],
      "metadata": {
        "id": "6kh2OhNyc7cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Creating groups of ID per mean"
      ],
      "metadata": {
        "id": "xdx5BNjZfbe8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Empezamos creando dos grupos de ID iniciales, el primero de ellos mayor a 2000 y el segundo entre 1000 a 2000"
      ],
      "metadata": {
        "id": "Jm-sMevIf3GH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "group_2000=describe_by_dates.T[describe_by_dates.T['mean']>2000]\n",
        "group_1000_2000=describe_by_dates.T[(describe_by_dates.T['mean']>1000)&(describe_by_dates.T['mean']<2000)]\n",
        "print('>2000',group_2000.shape)\n",
        "print('1000>ID<2000',group_1000_2000.shape)\n",
        "rest_df=describe_by_dates.T[describe_by_dates.T['mean']<=1000]\n",
        "rest_df"
      ],
      "metadata": {
        "id": "1smiai0cfGl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rest_df.describe()"
      ],
      "metadata": {
        "id": "kgk15hwRg0V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya que los ID tienen tanta variabilidad entre ellos se ha decidido agrupar por grupos"
      ],
      "metadata": {
        "id": "iaWA2-kJdvaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.distplot(\n",
        "    rest_df['mean'], norm_hist=False, kde=False, bins=50, hist_kws={\"alpha\": 1}\n",
        ").set(xlabel='Sale Price', ylabel='Count');"
      ],
      "metadata": {
        "id": "NXlGN0N9d3X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rest_df['group_by_mean_in_total']=pd.qcut(rest_df['mean'],q=50,labels=range(50))\n",
        "group_1000_2000['group_by_mean_in_total']=50\n",
        "group_2000['group_by_mean_in_total']=51"
      ],
      "metadata": {
        "id": "K8kQdm6MiYQm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_group_by_mean_in_total=pd.concat([rest_df,group_1000_2000,group_2000])['group_by_mean_in_total']\n",
        "df_with_group_by_mean_in_total.head()"
      ],
      "metadata": {
        "id": "8nD6qjOOkDBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_with_group_by_mean_in_total.to_csv('group_by_mean_in_total.csv')"
      ],
      "metadata": {
        "id": "bzziEWQAkmpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Plotting a fews plots"
      ],
      "metadata": {
        "id": "kB106NVOBNBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_total_with_bins=pd.merge(df_with_group_by_mean_in_total,df_total,how='right',left_index=True,right_on='ID')\n"
      ],
      "metadata": {
        "id": "g9PQhKhekijR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a8pESTTHjbP"
      },
      "outputs": [],
      "source": [
        "#@title plot id per year\n",
        "id_per_plot = 10 #@param {type:\"number\"}\n",
        "plt.figure(figsize=(20,5))\n",
        "for i, id_unique in tqdm(enumerate(df_total_with_bins.sort_values(['group_by_mean_in_total','date']).ID.unique()),desc=\"creating plots\"):\n",
        "    \n",
        "    df_aux=df_total_with_bins[df_total_with_bins['ID'] == id_unique]\n",
        "    bin=df_aux['group_by_mean_in_total'].unique()[0]\n",
        "    plot_series(df_aux.index,df_aux['total'],id_unique)\n",
        "    \n",
        "    if i %id_per_plot==0:\n",
        "        plt.title(f'This bin {str(bin)}')\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(20,5))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "En las gráficas se ve que el id 353 y 2711 hay que corregirlos, siendo en el 353 poniendo los picos a 0 y en el 2711 probablemente poniendolo en positivo el valor negativo y recalcular lo de los bins"
      ],
      "metadata": {
        "id": "sjEqldfAuUts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Análisis de dependencia por correlación entre los distintos ID"
      ],
      "metadata": {
        "id": "Hi_7RPF_vF0t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_by_dates.head()"
      ],
      "metadata": {
        "id": "XOfa-FTSvdKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "corr_matrix = pivot_by_dates.corr()\n",
        "\n",
        "corr = ((corr_matrix + corr_matrix.T)/2 ).values                        # made symmetric\n",
        "np.fill_diagonal(corr, 1)  "
      ],
      "metadata": {
        "id": "caGoQ659wLiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "data_to_correlation=pivot_by_dates.copy()\n",
        "# data_to_correlation.drop(['ID'],axis=1,inplace=True)\n",
        "corr_matrix = data_to_correlation.corr()\n",
        " # Select upper triangle of correlation matrix\n",
        "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
        "s = upper.unstack()\n",
        "so = s.sort_values(kind=\"quicksort\")\n",
        "to_use_in_next_study = so[so>0.8]\n",
        "to_use_in_next_study"
      ],
      "metadata": {
        "id": "t1P8kfL0vTFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "# ids=[2733,2727,2735,2731,2736  ]\n",
        "# ids=[2739,2735,2733,2731,2736]\n",
        "# ids=[1498,42]\n",
        "# ids=[87,21]\n",
        "ids=[2652,2658]\n",
        "for ids,corr in to_use_in_next_study.iteritems():\n",
        "    print(ids,corr)\n",
        "    for i, id_unique in tqdm(enumerate(df_total_with_bins[df_total_with_bins.ID.isin(ids)].sort_values(['group_by_mean_in_total','date']).ID.unique()),desc=\"creating plots\"):\n",
        "        print(id_unique)\n",
        "        df_aux=df_total_with_bins[df_total_with_bins['ID'] == id_unique]\n",
        "        bin=df_aux['group_by_mean_in_total'].unique()[0]\n",
        "        plot_series(df_aux.index,df_aux['total'],id_unique)\n",
        "        \n",
        "        # if i %id_per_plot==0 and i>0:\n",
        "    plt.title(f'This bin {str(bin)}')\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(20,5))"
      ],
      "metadata": {
        "id": "ZArJDq3oycoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esto nos da información sobre variables que son similares a otras variables, por lo que deberíamos de utilizar esta información en el modelo en algún momento"
      ],
      "metadata": {
        "id": "-TwcgNjK1w2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "so.head(50)"
      ],
      "metadata": {
        "id": "i1bXQDBTyEa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##trends and stacionality"
      ],
      "metadata": {
        "id": "N5Fc-OI5vTdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###using statsmodels"
      ],
      "metadata": {
        "id": "tGMX-Dsu2yJ0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHEO2goN1w3S"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "from matplotlib import rcParams\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_by_dates[2].plot()"
      ],
      "metadata": {
        "id": "8Hf9iyoAzqR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_per_plots=1\n",
        "plt.figure(figsize=(20,15))\n",
        "for i,ts in enumerate(pivot_by_dates.columns):\n",
        "    decomposition = sm.tsa.seasonal_decompose(pivot_by_dates[ts].dropna())\n",
        "    # Store back the results\n",
        "    data = decomposition.seasonal\n",
        "    plot_series(data.index,data.values,ts)\n",
        "    if i%id_per_plots==0 and i>=id_per_plots:\n",
        "\n",
        "        plt.title(f'id between {str(i)}')\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(20,15))\n",
        "    if i >=100:\n",
        "        break"
      ],
      "metadata": {
        "id": "fPAiEkqZ0bvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQaq6b0ozCQt"
      },
      "outputs": [],
      "source": [
        "id_per_plots=10\n",
        "plt.figure(figsize=(20,15))\n",
        "for i,ts in enumerate(pivot_by_dates.columns):\n",
        "    decomposition = sm.tsa.seasonal_decompose(pivot_by_dates[ts].dropna())\n",
        "    # Store back the results\n",
        "    data = decomposition.trend\n",
        "    plot_series(data.index,data.values,ts)\n",
        "    if i%id_per_plots==0 and i>8:\n",
        "\n",
        "        plt.title(f'id between {str(i)}')\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(20,15))\n",
        "    if i >=100:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_per_plots=10\n",
        "plt.figure(figsize=(20,15))\n",
        "for i,ts in enumerate(pivot_by_dates.columns):\n",
        "    decomposition = sm.tsa.seasonal_decompose(pivot_by_dates[ts].dropna())\n",
        "    # Store back the results\n",
        "    data = decomposition.resid\n",
        "    plot_series(data.index,data.values,ts)\n",
        "    if i%id_per_plots==0 and i>8:\n",
        "\n",
        "        plt.title(f'id between {str(i)}')\n",
        "        plt.show()\n",
        "        plt.figure(figsize=(20,15))\n",
        "    if i >=100:\n",
        "        break"
      ],
      "metadata": {
        "id": "oSTt6D7W0pni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics import tsaplots\n",
        "id_per_plots=10\n",
        "plt.figure(figsize=(20,15))\n",
        "for i,ts in enumerate(pivot_by_dates.columns):\n",
        "    tsaplots.plot_acf(pivot_by_dates[ts], lags=90)\n",
        "    \n",
        "    plt.xlabel(\"Lag at k\")\n",
        "    plt.ylabel(\"Correlation coefficient\")\n",
        "    plt.title(f'id between {str(i)}')\n",
        "    plt.show()\n",
        "    plt.figure(figsize=(20,5))\n",
        "    if i >=100:\n",
        "        break"
      ],
      "metadata": {
        "id": "JeYNHFnsNYNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.seasonal import STL\n",
        "id_per_plots=10\n",
        "for i,ts in enumerate(pivot_by_dates.columns):\n",
        "    res=STL(pivot_by_dates[ts],).fit()\n",
        "    fig=res.plot()\n",
        "    fig.set_figheight(10)\n",
        "    fig.set_figwidth(20)\n",
        "    plt.xlabel(\"Lag at k\")\n",
        "    plt.ylabel(\"Correlation coefficient\")\n",
        "    plt.title(f'id between {str(i)}')\n",
        "    plt.show()\n",
        "    print('\\n')\n",
        "    if i >=100:\n",
        "        break"
      ],
      "metadata": {
        "id": "SJchoP86Agwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "id": "9aO69EH-A0NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qINp3GPtht3G"
      },
      "source": [
        "###using prophet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_by_dates.plot()"
      ],
      "metadata": {
        "id": "1s7uqjbjRfxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NanSQzewhzM9"
      },
      "outputs": [],
      "source": [
        "df_prophet=pd.DataFrame()\n",
        "df_aux=pivot_by_dates[81]\n",
        "df_prophet[['ds','y']]=df_aux.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_prophet"
      ],
      "metadata": {
        "id": "a4MKqaxQRJJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solo mostramos los 20 primeros"
      ],
      "metadata": {
        "id": "ftioTRfd8EDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Iu_etMBisyC"
      },
      "outputs": [],
      "source": [
        "for i,ts in tqdm(enumerate(pivot_by_dates.columns)): \n",
        "    df_prophet=pd.DataFrame()\n",
        "    df_aux=pivot_by_dates[ts]\n",
        "    df_prophet[['ds','y']]=df_aux.reset_index()\n",
        "    m = Prophet(yearly_seasonality=False,\n",
        "        weekly_seasonality=True,\n",
        "        daily_seasonality=False\n",
        "        )\n",
        "    m.fit(df_prophet)\n",
        "    forecast = m.predict(df_prophet)\n",
        "    fig1 = m.plot(forecast)\n",
        "    fig1.suptitle('id '+str(ts))\n",
        "    fig1.show()\n",
        "    print(\"\\n\"*1)\n",
        "    fig2 = m.plot_components(forecast)\n",
        "    fig2.suptitle('id '+str(ts))\n",
        "    print(\"\\n\"*3)\n",
        "    if i>20:\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### with pycaret --> time series"
      ],
      "metadata": {
        "id": "OouX9RRw4ZQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pycaret import time_series"
      ],
      "metadata": {
        "id": "WFR7S-y64k3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_eD6HDpOPQE"
      },
      "outputs": [],
      "source": [
        "pivot_by_dates\n",
        "data_to_exp=pivot_by_dates[2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_exp.head()"
      ],
      "metadata": {
        "id": "7pcdhyKw-Yyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fh=7"
      ],
      "metadata": {
        "id": "-JFQV9fLC1DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title análisis exhaustivo de un id específico\n",
        "id_specifico = 2 #@param {type:\"integer\"}\n",
        "df_aux=pivot_by_dates[id_specifico]\n",
        "\n",
        "time_series.setup( data_to_exp,fh=7 )\n",
        "####Original dataset\n",
        "time_series.plot_model()\n",
        "print(\"\\n\"*1)\n",
        "print(f'id {ts}')\n",
        "#### ACF and PACF for the original dataset\n",
        "time_series.plot_model(plot=\"acf\")\n",
        "print(f'id {ts}')\n",
        "\n",
        "time_series.plot_model(plot=\"decomp_classical\")\n",
        "print(f'id {ts}')\n",
        "try:\n",
        "    time_series.plot_model(plot=\"decomp_classical\", data_kwargs={'type': 'multiplicative'})\n",
        "    print(f'id {ts}')\n",
        "except: \n",
        "    pass\n",
        "time_series.plot_model(plot=\"decomp_stl\")\n",
        "print(f'id {ts}')\n",
        "# Show the train-test splits on the dataset\n",
        "# Internally split - len(fh) as test set, remaining used as test set\n",
        "time_series.plot_model(plot=\"train_test_split\")\n",
        "print(f'id {ts}')\n",
        "\n",
        "# Show the Cross Validation splits inside the train set\n",
        "time_series.plot_model(plot=\"cv\")\n",
        "print(f'id {ts}')\n",
        "# Plot diagnostics\n",
        "time_series.plot_model(plot=\"diagnostics\")\n",
        "print(f'id {ts}')\n",
        "# Plot differences along with diagnostics such as ACF and PACF\n",
        "\n",
        "# Row 1: Original\n",
        "# Row 2: d = 1\n",
        "# Row 3: d = 2\n",
        "time_series.plot_model(plot=\"diff\", data_kwargs={\"order_list\": [1, 2], \"pacf\": True})\n",
        "print(f'id {ts}')\n",
        "\n",
        "# Row 1: Original\n",
        "# Row 2: d = 1\n",
        "# Row 3: First (d = 1) then (D = 1, s = 12)\n",
        "#   - Corresponds to applying a standard first difference to handle trend, and\n",
        "#     followed by a seasonal difference (at lag 12) to attempt to account for\n",
        "#     seasonal dependence.\n",
        "# Ref: https://www.sktime.org/en/v0.8.0/api_reference/modules/auto_generated/sktime.transformations.series.difference.Differencer.html\n",
        "time_series.plot_model(plot=\"diff\", data_kwargs={\"lags_list\": [[1], [1, 12]], \"acf\": True, \"pacf\": True})\n",
        "print(f'id {ts}')\n",
        "\n"
      ],
      "metadata": {
        "id": "pSgfdRG4Cvnj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Análisis exploratorio Cajamar2022.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}